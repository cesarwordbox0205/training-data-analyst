{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kubeflow pipelines\n",
    "\n",
    "This notebook goes through the steps of using Kubeflow pipelines using the Python3 interpreter (command-line) to preprocess, train, tune and deploy the babyweight model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start Hosted Pipelines and Notebook\n",
    "\n",
    "To try out this notebook, first launch Kubeflow Hosted Pipelines and an AI Platform Notebooks instance.\n",
    "Follow the instructions in this [README.md](pipelines/README.md) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --quiet kfp python-dateutil --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to *restart the kernel* to pick up new packages (look for button in the ribbon of icons above this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Connect to the Hosted Pipelines\n",
    "\n",
    "Visit https://console.cloud.google.com/ai-platform/pipelines/clusters\n",
    "and get the hostname for your cluster.  You can get it by clicking on the Settings icon.\n",
    "Alternately, click on the Open Pipelines Dashboard link and look at the URL.\n",
    "Change the settings in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE\n",
    "PIPELINES_HOST='7d7bd1724973ff3f-dot-us-central1.pipelines.googleusercontent.com'\n",
    "PROJECT='youtubelist-256522'\n",
    "BUCKET='cesar-pipelines-kfp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'next_page_token': None,\n",
       " 'pipelines': [{'created_at': datetime.datetime(2021, 3, 6, 22, 24, 28, tzinfo=tzlocal()),\n",
       "                'default_version': {'code_source_url': None,\n",
       "                                    'created_at': datetime.datetime(2021, 3, 6, 22, 24, 28, tzinfo=tzlocal()),\n",
       "                                    'id': 'e132cdf3-aebe-46f6-bded-f63e5f5e7f67',\n",
       "                                    'name': '[Demo] XGBoost - Iterative model '\n",
       "                                            'training',\n",
       "                                    'package_url': None,\n",
       "                                    'parameters': None,\n",
       "                                    'resource_references': [{'key': {'id': 'e132cdf3-aebe-46f6-bded-f63e5f5e7f67',\n",
       "                                                                     'type': 'PIPELINE'},\n",
       "                                                             'name': None,\n",
       "                                                             'relationship': 'OWNER'}]},\n",
       "                'description': '[source '\n",
       "                               'code](https://github.com/kubeflow/pipelines/blob/d79071c0bef19442483abc101769a0d893e72f42/samples/core/train_until_good/train_until_good.py) '\n",
       "                               'This sample demonstrates iterative training '\n",
       "                               'using a train-eval-check recursive loop. The '\n",
       "                               'main pipeline trains the initial model and '\n",
       "                               'then gradually trains the model some more '\n",
       "                               'until the model evaluation metrics are good '\n",
       "                               'enough.',\n",
       "                'error': None,\n",
       "                'id': 'e132cdf3-aebe-46f6-bded-f63e5f5e7f67',\n",
       "                'name': '[Demo] XGBoost - Iterative model training',\n",
       "                'parameters': None,\n",
       "                'url': None},\n",
       "               {'created_at': datetime.datetime(2021, 3, 6, 22, 24, 29, tzinfo=tzlocal()),\n",
       "                'default_version': {'code_source_url': None,\n",
       "                                    'created_at': datetime.datetime(2021, 3, 6, 22, 24, 29, tzinfo=tzlocal()),\n",
       "                                    'id': '9e3bffae-1137-47f8-8bff-c7af31ffb1d2',\n",
       "                                    'name': '[Demo] TFX - Taxi tip prediction '\n",
       "                                            'model trainer',\n",
       "                                    'package_url': None,\n",
       "                                    'parameters': [{'name': 'pipeline-root',\n",
       "                                                    'value': 'gs://{{kfp-default-bucket}}/tfx_taxi_simple/{{workflow.uid}}'},\n",
       "                                                   {'name': 'data-root',\n",
       "                                                    'value': 'gs://ml-pipeline/sample-data/chicago-taxi/data'},\n",
       "                                                   {'name': 'module-file',\n",
       "                                                    'value': '/tfx/src/tfx/examples/chicago_taxi_pipeline/taxi_utils.py'}],\n",
       "                                    'resource_references': [{'key': {'id': '9e3bffae-1137-47f8-8bff-c7af31ffb1d2',\n",
       "                                                                     'type': 'PIPELINE'},\n",
       "                                                             'name': None,\n",
       "                                                             'relationship': 'OWNER'}]},\n",
       "                'description': '[source '\n",
       "                               'code](https://github.com/kubeflow/pipelines/tree/d79071c0bef19442483abc101769a0d893e72f42/samples/core/parameterized_tfx_oss) '\n",
       "                               '[GCP Permission '\n",
       "                               'requirements](https://github.com/kubeflow/pipelines/blob/d79071c0bef19442483abc101769a0d893e72f42/samples/core/parameterized_tfx_oss#permission). '\n",
       "                               'Example pipeline that does classification with '\n",
       "                               'model analysis based on a public tax cab '\n",
       "                               'dataset.',\n",
       "                'error': None,\n",
       "                'id': '9e3bffae-1137-47f8-8bff-c7af31ffb1d2',\n",
       "                'name': '[Demo] TFX - Taxi tip prediction model trainer',\n",
       "                'parameters': [{'name': 'pipeline-root',\n",
       "                                'value': 'gs://{{kfp-default-bucket}}/tfx_taxi_simple/{{workflow.uid}}'},\n",
       "                               {'name': 'data-root',\n",
       "                                'value': 'gs://ml-pipeline/sample-data/chicago-taxi/data'},\n",
       "                               {'name': 'module-file',\n",
       "                                'value': '/tfx/src/tfx/examples/chicago_taxi_pipeline/taxi_utils.py'}],\n",
       "                'url': None},\n",
       "               {'created_at': datetime.datetime(2021, 3, 6, 22, 24, 30, tzinfo=tzlocal()),\n",
       "                'default_version': {'code_source_url': None,\n",
       "                                    'created_at': datetime.datetime(2021, 3, 6, 22, 24, 30, tzinfo=tzlocal()),\n",
       "                                    'id': '733230b1-dde2-42a7-a0f1-b723745161b9',\n",
       "                                    'name': '[Tutorial] Data passing in python '\n",
       "                                            'components',\n",
       "                                    'package_url': None,\n",
       "                                    'parameters': None,\n",
       "                                    'resource_references': [{'key': {'id': '733230b1-dde2-42a7-a0f1-b723745161b9',\n",
       "                                                                     'type': 'PIPELINE'},\n",
       "                                                             'name': None,\n",
       "                                                             'relationship': 'OWNER'}]},\n",
       "                'description': '[source '\n",
       "                               'code](https://github.com/kubeflow/pipelines/tree/d79071c0bef19442483abc101769a0d893e72f42/samples/tutorials/Data%20passing%20in%20python%20components) '\n",
       "                               'Shows how to pass data between python '\n",
       "                               'components.',\n",
       "                'error': None,\n",
       "                'id': '733230b1-dde2-42a7-a0f1-b723745161b9',\n",
       "                'name': '[Tutorial] Data passing in python components',\n",
       "                'parameters': None,\n",
       "                'url': None},\n",
       "               {'created_at': datetime.datetime(2021, 3, 6, 22, 24, 31, tzinfo=tzlocal()),\n",
       "                'default_version': {'code_source_url': None,\n",
       "                                    'created_at': datetime.datetime(2021, 3, 6, 22, 24, 31, tzinfo=tzlocal()),\n",
       "                                    'id': '9e3b2daf-20c4-4dbd-8fbd-67deeb498b49',\n",
       "                                    'name': '[Tutorial] DSL - Control '\n",
       "                                            'structures',\n",
       "                                    'package_url': None,\n",
       "                                    'parameters': None,\n",
       "                                    'resource_references': [{'key': {'id': '9e3b2daf-20c4-4dbd-8fbd-67deeb498b49',\n",
       "                                                                     'type': 'PIPELINE'},\n",
       "                                                             'name': None,\n",
       "                                                             'relationship': 'OWNER'}]},\n",
       "                'description': '[source '\n",
       "                               'code](https://github.com/kubeflow/pipelines/tree/d79071c0bef19442483abc101769a0d893e72f42/samples/tutorials/DSL%20-%20Control%20structures) '\n",
       "                               'Shows how to use conditional execution and '\n",
       "                               'exit handlers. This pipeline will randomly '\n",
       "                               'fail to demonstrate that the exit handler gets '\n",
       "                               'executed even in case of failure.',\n",
       "                'error': None,\n",
       "                'id': '9e3b2daf-20c4-4dbd-8fbd-67deeb498b49',\n",
       "                'name': '[Tutorial] DSL - Control structures',\n",
       "                'parameters': None,\n",
       "                'url': None}],\n",
       " 'total_size': 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kfp\n",
    "import os\n",
    "client = kfp.Client(host=PIPELINES_HOST)\n",
    "client.list_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [Optional] Build Docker containers\n",
    "\n",
    "I have made my containers public (See https://cloud.google.com/container-registry/docs/access-control on how to do this), so you can simply use my images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Docker container in traintuned\n",
      "Creating babyweight-pipeline-traintuned:latest from this Dockerfile:\n",
      "# Copyright 2018 The Kubeflow Authors\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "FROM gcr.io/ml-pipeline/ml-pipeline-kubeflow-trainer:0.0.18\n",
      "#FROM tensorflow/tensorflow:1.11.0-py3\n",
      "\n",
      "RUN apt-get update -y && apt-get install --no-install-recommends -y -q ca-certificates python-dev python-setuptools wget unzip git\n",
      "\n",
      "RUN easy_install pip\n",
      "\n",
      "RUN pip install google-api-python-client\n",
      "\n",
      "RUN cd / && \\\n",
      "    wget -nv https://dl.google.com/dl/cloudsdk/release/google-cloud-sdk.zip && \\\n",
      "    unzip -qq google-cloud-sdk.zip -d tools && \\\n",
      "    rm google-cloud-sdk.zip && \\\n",
      "    tools/google-cloud-sdk/install.sh --usage-reporting=false \\\n",
      "        --path-update=false --bash-completion=false \\\n",
      "        --disable-installation-options && \\\n",
      "    tools/google-cloud-sdk/bin/gcloud -q components update \\\n",
      "        gcloud core gsutil && \\\n",
      "    tools/google-cloud-sdk/bin/gcloud config set component_manager/disable_update_check true && \\\n",
      "    touch /tools/google-cloud-sdk/lib/third_party/google.py\n",
      "\n",
      "ENV PATH $PATH:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
      "\n",
      "RUN mkdir -p /babyweight/src && \\\n",
      "    cd /babyweight/src && \\\n",
      "    git clone https://github.com/cesarwordbox0205/training-data-analyst && \\\n",
      "    rm -rf /ml/trainer\n",
      "\n",
      "COPY train.sh ./\n",
      "\n",
      "ENTRYPOINT [\"bash\", \"./train.sh\"]\n",
      "steps:\n",
      "    - name: 'gcr.io/cloud-builders/docker'\n",
      "      args: [ 'build', '-t', 'gcr.io/youtubelist-256522/babyweight-pipeline-traintuned:latest', '.' ]\n",
      "images:\n",
      "    - 'gcr.io/youtubelist-256522/babyweight-pipeline-traintuned:latest'\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"fc70c8e5-4066-4eb9-bc0f-82e4926f9a43\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://youtubelist-256522_cloudbuild/source/1615185559.530601-71e7af90612c4339bf82bee14bbed4db.tgz#1615185559986112\n",
      "Copying gs://youtubelist-256522_cloudbuild/source/1615185559.530601-71e7af90612c4339bf82bee14bbed4db.tgz#1615185559986112...\n",
      "/ [1 files][  3.5 KiB/  3.5 KiB]                                                \n",
      "Operation completed over 1 objects/3.5 KiB.                                      \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  26.62kB\n",
      "Step 1/9 : FROM gcr.io/ml-pipeline/ml-pipeline-kubeflow-trainer:0.0.18\n",
      "0.0.18: Pulling from ml-pipeline/ml-pipeline-kubeflow-trainer\n",
      "3b37166ec614: Pulling fs layer\n",
      "504facff238f: Pulling fs layer\n",
      "ebbcacd28e10: Pulling fs layer\n",
      "c7fb3351ecad: Pulling fs layer\n",
      "2e3debadcbf7: Pulling fs layer\n",
      "7a92c348bf29: Pulling fs layer\n",
      "a97804a067f1: Pulling fs layer\n",
      "a2c9f6414d9a: Pulling fs layer\n",
      "9db864234164: Pulling fs layer\n",
      "62c65db5fd23: Pulling fs layer\n",
      "f242ae417e4f: Pulling fs layer\n",
      "c7fb3351ecad: Waiting\n",
      "2e3debadcbf7: Waiting\n",
      "7a92c348bf29: Waiting\n",
      "a97804a067f1: Waiting\n",
      "a2c9f6414d9a: Waiting\n",
      "9db864234164: Waiting\n",
      "62c65db5fd23: Waiting\n",
      "f242ae417e4f: Waiting\n",
      "504facff238f: Download complete\n",
      "ebbcacd28e10: Verifying Checksum\n",
      "ebbcacd28e10: Download complete\n",
      "2e3debadcbf7: Verifying Checksum\n",
      "2e3debadcbf7: Download complete\n",
      "c7fb3351ecad: Verifying Checksum\n",
      "c7fb3351ecad: Download complete\n",
      "3b37166ec614: Verifying Checksum\n",
      "3b37166ec614: Download complete\n",
      "a2c9f6414d9a: Verifying Checksum\n",
      "a2c9f6414d9a: Download complete\n",
      "7a92c348bf29: Verifying Checksum\n",
      "7a92c348bf29: Download complete\n",
      "62c65db5fd23: Verifying Checksum\n",
      "62c65db5fd23: Download complete\n",
      "f242ae417e4f: Verifying Checksum\n",
      "f242ae417e4f: Download complete\n",
      "a97804a067f1: Verifying Checksum\n",
      "a97804a067f1: Download complete\n",
      "9db864234164: Verifying Checksum\n",
      "9db864234164: Download complete\n",
      "3b37166ec614: Pull complete\n",
      "504facff238f: Pull complete\n",
      "ebbcacd28e10: Pull complete\n",
      "c7fb3351ecad: Pull complete\n",
      "2e3debadcbf7: Pull complete\n",
      "7a92c348bf29: Pull complete\n",
      "a97804a067f1: Pull complete\n",
      "a2c9f6414d9a: Pull complete\n",
      "9db864234164: Pull complete\n",
      "62c65db5fd23: Pull complete\n",
      "f242ae417e4f: Pull complete\n",
      "Digest: sha256:31172b069d330f76d5d67890efb188343dd42ee3e7c4f422f147f271de56f9cd\n",
      "Status: Downloaded newer image for gcr.io/ml-pipeline/ml-pipeline-kubeflow-trainer:0.0.18\n",
      " ---> 941b1b17ce9c\n",
      "Step 2/9 : RUN apt-get update -y && apt-get install --no-install-recommends -y -q ca-certificates python-dev python-setuptools wget unzip git\n",
      " ---> Running in 276583583d6a\n",
      "Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu xenial InRelease\n",
      "Get:3 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu xenial-security/universe Sources [256 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu xenial-updates/universe Sources [547 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [1949 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [2457 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [15.9 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [984 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [8820 B]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial-updates/restricted amd64 Packages [16.4 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [1539 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 Packages [26.2 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial-backports/main amd64 Packages [10.9 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-backports/universe amd64 Packages [12.6 kB]\n",
      "Fetched 8149 kB in 2s (3489 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "python-setuptools is already the newest version (20.7.0-1).\n",
      "python-dev is already the newest version (2.7.12-1~16.04).\n",
      "Suggested packages:\n",
      "  gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-el git-email\n",
      "  git-gui gitk gitweb git-arch git-cvs git-mediawiki git-svn zip\n",
      "Recommended packages:\n",
      "  less rsync ssh-client\n",
      "The following packages will be upgraded:\n",
      "  ca-certificates git unzip wget\n",
      "4 upgraded, 0 newly installed, 0 to remove and 75 not upgraded.\n",
      "Need to get 3784 kB of archives.\n",
      "After this operation, 21.5 kB disk space will be freed.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 ca-certificates all 20210119~16.04.1 [148 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 wget amd64 1.17.1-1ubuntu1.5 [299 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 git amd64 1:2.7.4-0ubuntu1.9 [3176 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 unzip amd64 6.0-20ubuntu1.1 [162 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 3784 kB in 1s (2452 kB/s)\n",
      "(Reading database ... 10297 files and directories currently installed.)\n",
      "Preparing to unpack .../ca-certificates_20210119~16.04.1_all.deb ...\n",
      "Unpacking ca-certificates (20210119~16.04.1) over (20170717~16.04.1) ...\n",
      "Preparing to unpack .../wget_1.17.1-1ubuntu1.5_amd64.deb ...\n",
      "Unpacking wget (1.17.1-1ubuntu1.5) over (1.17.1-1ubuntu1.4) ...\n",
      "Preparing to unpack .../git_1%3a2.7.4-0ubuntu1.9_amd64.deb ...\n",
      "Unpacking git (1:2.7.4-0ubuntu1.9) over (1:2.7.4-0ubuntu1.4) ...\n",
      "Preparing to unpack .../unzip_6.0-20ubuntu1.1_amd64.deb ...\n",
      "Unpacking unzip (6.0-20ubuntu1.1) over (6.0-20ubuntu1) ...\n",
      "Processing triggers for mime-support (3.59ubuntu1) ...\n",
      "Setting up ca-certificates (20210119~16.04.1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up wget (1.17.1-1ubuntu1.5) ...\n",
      "Setting up git (1:2.7.4-0ubuntu1.9) ...\n",
      "Setting up unzip (6.0-20ubuntu1.1) ...\n",
      "Processing triggers for ca-certificates (20210119~16.04.1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "31 added, 50 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "done.\n",
      "Removing intermediate container 276583583d6a\n",
      " ---> e04b250f4d2b\n",
      "Step 3/9 : RUN easy_install pip\n",
      " ---> Running in 2769e968420b\n",
      "Searching for pip\n",
      "Best match: pip 18.0\n",
      "Processing pip-18.0-py2.7.egg\n",
      "pip 18.0 is already the active version in easy-install.pth\n",
      "Installing pip script to /usr/local/bin\n",
      "Installing pip2.7 script to /usr/local/bin\n",
      "Installing pip2 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python2.7/dist-packages/pip-18.0-py2.7.egg\n",
      "Processing dependencies for pip\n",
      "Finished processing dependencies for pip\n",
      "Removing intermediate container 2769e968420b\n",
      " ---> 91b5b0302146\n",
      "Step 4/9 : RUN pip install google-api-python-client\n",
      " ---> Running in b6b14ede227d\n",
      "Collecting google-api-python-client\n",
      "  Downloading https://files.pythonhosted.org/packages/83/fc/98045b8c5e0ba12929d423e9ff6b742951bb846707539b18f19b27c6ddc3/google_api_python_client-1.12.8-py2.py3-none-any.whl (61kB)\n",
      "Collecting google-auth>=1.16.0 (from google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/2f/1aa41b81d8ed16c22c02dbc7a1c9890dc81f826958063d7e2ae16f475a5e/google_auth-1.27.1-py2.py3-none-any.whl (136kB)\n",
      "Collecting google-api-core<2dev,>=1.21.0 (from google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/72/1dfc9233b3cc2b3e2a1d2839e18f2ced8fe9586425aaa13483d47cef542b/google_api_core-1.26.1-py2.py3-none-any.whl (92kB)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3)\n",
      "Collecting httplib2<1dev,>=0.15.0 (from google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/ef/f0e05d5886a9c25dea4b18be06cd7bcaddbae0168cc576f3568f9bd6a35a/httplib2-0.19.0.tar.gz (263kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/0c/60d82c077998feb631608dca3cc1fe19ac074e772bf0c24cf409b977b815/uritemplate-3.0.1-py2.py3-none-any.whl\n",
      "Collecting six<2dev,>=1.13.0 (from google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting setuptools>=40.3.0 (from google-auth>=1.16.0->google-api-python-client)\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/b7/182161210a13158cd3ccc41ee19aadef54496b74f2817cc147006ec932b4/setuptools-44.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: rsa<4.6; python_version < \"3.6\" in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (2.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (0.2.2)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core<2dev,>=1.21.0->google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/74/3956721ea1eb4bcf7502a311fdaa60b85bd751de4e57d1943afe9b334141/googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100kB)\n",
      "Collecting protobuf>=3.12.0 (from google-api-core<2dev,>=1.21.0->google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/8d/5014075ce293ed6047397e8e9747d7720c2f9f67c4113506330990bd1e19/protobuf-3.15.5-cp27-cp27mu-manylinux1_x86_64.whl (1.0MB)\n",
      "Requirement already satisfied: futures>=3.2.0; python_version < \"3.2\" in /usr/local/lib/python2.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (3.2.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python2.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2018.4)\n",
      "Collecting packaging>=14.3 (from google-api-core<2dev,>=1.21.0->google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/3e/89/7ea760b4daa42653ece2380531c90f64788d979110a2ab51049d92f408af/packaging-20.9-py2.py3-none-any.whl (40kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python2.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2.19.1)\n",
      "Collecting pyparsing<3,>=2.4.2 (from httplib2<1dev,>=0.15.0->google-api-python-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl (67kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa<4.6; python_version < \"3.6\"->google-auth>=1.16.0->google-api-python-client) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2018.8.24)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (1.23)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.7)\n",
      "Building wheels for collected packages: httplib2\n",
      "  Running setup.py bdist_wheel for httplib2: started\n",
      "  Running setup.py bdist_wheel for httplib2: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/39/c7/564ec834f676f0ac0d8d95f88c6a2bc86e7ba50353fa53defa\n",
      "Successfully built httplib2\n",
      "\u001b[91mgapic-google-cloud-pubsub-v1 0.15.4 has requirement oauth2client<4.0dev,>=2.0.0, but you'll have oauth2client 4.1.3 which is incompatible.\n",
      "proto-google-cloud-pubsub-v1 0.15.4 has requirement oauth2client<4.0dev,>=2.0.0, but you'll have oauth2client 4.1.3 which is incompatible.\n",
      "\u001b[0m\u001b[91mgrpc-google-iam-v1 0.11.1 has requirement oauth2client<4.0.0dev,>=2.0.0, but you'll have oauth2client 4.1.3 which is incompatible.\n",
      "apache-beam 2.6.0 has requirement httplib2<=0.11.3,>=0.8, but you'll have httplib2 0.19.0 which is incompatible.\n",
      "apache-beam 2.6.0 has requirement six<1.12,>=1.9, but you'll have six 1.15.0 which is incompatible.\n",
      "proto-google-cloud-datastore-v1 0.90.4 has requirement oauth2client<4.0dev,>=2.0.0, but you'll have oauth2client 4.1.3 which is incompatible.\n",
      "\u001b[0m\u001b[91mgoogledatastore 7.0.1 has requirement httplib2<0.10,>=0.9.1, but you'll have httplib2 0.19.0 which is incompatible.\n",
      "googledatastore 7.0.1 has requirement oauth2client<4.0.0,>=2.0.1, but you'll have oauth2client 4.1.3 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: setuptools, six, google-auth, protobuf, googleapis-common-protos, pyparsing, packaging, google-api-core, httplib2, uritemplate, google-api-python-client\n",
      "  Found existing installation: setuptools 20.7.0\n",
      "    Uninstalling setuptools-20.7.0:\n",
      "      Successfully uninstalled setuptools-20.7.0\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "  Found existing installation: google-auth 1.5.1\n",
      "    Uninstalling google-auth-1.5.1:\n",
      "      Successfully uninstalled google-auth-1.5.1\n",
      "  Found existing installation: protobuf 3.6.1\n",
      "    Uninstalling protobuf-3.6.1:\n",
      "      Successfully uninstalled protobuf-3.6.1\n",
      "  Found existing installation: googleapis-common-protos 1.5.3\n",
      "    Uninstalling googleapis-common-protos-1.5.3:\n",
      "      Successfully uninstalled googleapis-common-protos-1.5.3\n",
      "  Found existing installation: pyparsing 2.2.1\n",
      "    Uninstalling pyparsing-2.2.1:\n",
      "      Successfully uninstalled pyparsing-2.2.1\n",
      "  Found existing installation: httplib2 0.11.3\n",
      "    Uninstalling httplib2-0.11.3:\n",
      "      Successfully uninstalled httplib2-0.11.3\n",
      "Successfully installed google-api-core-1.26.1 google-api-python-client-1.12.8 google-auth-1.27.1 googleapis-common-protos-1.52.0 httplib2-0.19.0 packaging-20.9 protobuf-3.15.5 pyparsing-2.4.7 setuptools-44.1.1 six-1.15.0 uritemplate-3.0.1\n",
      "Removing intermediate container b6b14ede227d\n",
      " ---> 1da0094c1c7d\n",
      "Step 5/9 : RUN cd / &&     wget -nv https://dl.google.com/dl/cloudsdk/release/google-cloud-sdk.zip &&     unzip -qq google-cloud-sdk.zip -d tools &&     rm google-cloud-sdk.zip &&     tools/google-cloud-sdk/install.sh --usage-reporting=false         --path-update=false --bash-completion=false         --disable-installation-options &&     tools/google-cloud-sdk/bin/gcloud -q components update         gcloud core gsutil &&     tools/google-cloud-sdk/bin/gcloud config set component_manager/disable_update_check true &&     touch /tools/google-cloud-sdk/lib/third_party/google.py\n",
      " ---> Running in 5a7df75f8d3b\n",
      "\u001b[91m2021-03-08 06:40:18 URL:https://dl.google.com/dl/cloudsdk/release/google-cloud-sdk.zip [38033505/38033505] -> \"google-cloud-sdk.zip\" [1]\n",
      "\u001b[0mWelcome to the Google Cloud SDK!\n",
      "WARNING: You appear to be running this script as root. This may cause \n",
      "the installation to be inaccessible to users other than the root user.\n",
      "\u001b[91mBeginning update. This process may take several minutes.\n",
      "\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m\n",
      "Your current Cloud SDK version is: 330.0.0\n",
      "\u001b[0m\u001b[91mInstalling components from version: 330.0.0\n",
      "\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m+-----------------------------------------------------------------------------+\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m|                     These components will be installed.                     |\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m+-----------------------------------------------------+------------+----------+\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m|                         Name                        |  Version   |   Size   |\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m+-----------------------------------------------------+------------+----------+\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m| \u001b[0m\u001b[91mBigQuery Command Line Tool                         \u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m    2.0.65\u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m < 1 MiB\u001b[0m\u001b[91m \u001b[0m\u001b[91m|\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m| \u001b[0m\u001b[91mBigQuery Command Line Tool (Platform Specific)     \u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m    2.0.64\u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m < 1 MiB\u001b[0m\u001b[91m \u001b[0m\u001b[91m|\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m| \u001b[0m\u001b[91mCloud SDK Core Libraries (Platform Specific)       \u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m2021.02.05\u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m < 1 MiB\u001b[0m\u001b[91m \u001b[0m\u001b[91m|\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m| \u001b[0m\u001b[91mCloud Storage Command Line Tool                    \u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m      4.59\u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m 3.9 MiB\u001b[0m\u001b[91m \u001b[0m\u001b[91m|\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m| \u001b[0m\u001b[91mCloud Storage Command Line Tool (Platform Specific)\u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m      4.58\u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m < 1 MiB\u001b[0m\u001b[91m \u001b[0m\u001b[91m|\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m| \u001b[0m\u001b[91mKuberun                                            \u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m    0.0.11\u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m22.7 MiB\u001b[0m\u001b[91m \u001b[0m\u001b[91m|\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m| \u001b[0m\u001b[91manthoscli                                          \u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m     0.2.7\u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m51.7 MiB\u001b[0m\u001b[91m \u001b[0m\u001b[91m|\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m| \u001b[0m\u001b[91mgcloud cli dependencies                            \u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m2020.06.12\u001b[0m\u001b[91m \u001b[0m\u001b[91m| \u001b[0m\u001b[91m < 1 MiB\u001b[0m\u001b[91m \u001b[0m\u001b[91m|\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m+-----------------------------------------------------+------------+----------+\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91mFor the latest full release notes, please visit:\n",
      "  https://cloud.google.com/sdk/release_notes\n",
      "\n",
      "\u001b[0m\u001b[91m#============================================================#\n",
      "\u001b[0m\u001b[91m#= Creating update staging area                             =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m======\u001b[0m\u001b[91m======\u001b[0m\u001b[91m======\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: BigQuery Command Line Tool                   =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m===\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: BigQuery Command Line Tool (Platform Spec... =#\n",
      "#\u001b[0m\u001b[91m==============================\u001b[0m\u001b[91m==============================\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: Cloud SDK Core Libraries (Platform Specific) =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m==============================\u001b[0m\u001b[91m===============\u001b[0m\u001b[91m===============\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: Cloud Storage Command Line Tool              =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: Cloud Storage Command Line Tool (Platform... =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m==============================\u001b[0m\u001b[91m==============================\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: Default set of gcloud commands               =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m============================================================\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: Kuberun                                      =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m============================================================\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: Kuberun                                      =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m==\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m==\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m==\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m==\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: anthoscli                                    =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m============================================================\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: anthoscli                                    =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m=\u001b[0m\u001b[91m==========\u001b[0m\u001b[91m=========\u001b[0m\u001b[91m===========\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Installing: gcloud cli dependencies                      =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m==============================\u001b[0m\u001b[91m======\u001b[0m\u001b[91m======\u001b[0m\u001b[91m======\u001b[0m\u001b[91m======\u001b[0m\u001b[91m======\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m#= Creating backup and activating new installation          =#\n",
      "\u001b[0m\u001b[91m#\u001b[0m\u001b[91m==============================\u001b[0m\u001b[91m==============================\u001b[0m\u001b[91m#\n",
      "\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91mPerforming post processing steps...\n",
      "\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91mdone.\n",
      "\u001b[0m\u001b[91m\n",
      "Update done!\n",
      "\n",
      "\u001b[0m\n",
      "This will install all the core command line tools necessary for working with\n",
      "the Google Cloud Platform.\n",
      "\n",
      "\u001b[91m==> Source [/tools/google-cloud-sdk/completion.bash.inc] in your profile to enable shell command completion for gcloud.\n",
      "==> Source [/tools/google-cloud-sdk/path.bash.inc] in your profile to add the Google Cloud SDK command line tools to your $PATH.\n",
      "\u001b[0m\n",
      "For more information on how to get started, please visit:\n",
      "  https://cloud.google.com/sdk/docs/quickstarts\n",
      "\u001b[91mBeginning update. This process may take several minutes.\n",
      "\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91mAll components are up to date.\n",
      "\u001b[0m\u001b[91mUpdated property [component_manager/disable_update_check].\n",
      "\u001b[0mRemoving intermediate container 5a7df75f8d3b\n",
      " ---> 82ab7aa60720\n",
      "Step 6/9 : ENV PATH $PATH:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
      " ---> Running in e7b8ebf88869\n",
      "Removing intermediate container e7b8ebf88869\n",
      " ---> 25ff255b6811\n",
      "Step 7/9 : RUN mkdir -p /babyweight/src &&     cd /babyweight/src &&     git clone https://github.com/cesarwordbox0205/training-data-analyst &&     rm -rf /ml/trainer\n",
      " ---> Running in 6a1e7bd09e96\n",
      "\u001b[91mCloning into 'training-data-analyst'...\n",
      "\u001b[0mRemoving intermediate container 6a1e7bd09e96\n",
      " ---> 063e1ef35e3e\n",
      "Step 8/9 : COPY train.sh ./\n",
      " ---> 1ff0d4c1afae\n",
      "Step 9/9 : ENTRYPOINT [\"bash\", \"./train.sh\"]\n",
      " ---> Running in d92ca702c84d\n",
      "Removing intermediate container d92ca702c84d\n",
      " ---> deec6a8cad87\n",
      "Successfully built deec6a8cad87\n",
      "Successfully tagged gcr.io/youtubelist-256522/babyweight-pipeline-traintuned:latest\n",
      "PUSH\n",
      "Pushing gcr.io/youtubelist-256522/babyweight-pipeline-traintuned:latest\n",
      "The push refers to repository [gcr.io/youtubelist-256522/babyweight-pipeline-traintuned]\n",
      "58907d6c372e: Preparing\n",
      "fcc6929d67eb: Preparing\n",
      "b426a3435ac3: Preparing\n",
      "834ea553a725: Preparing\n",
      "07a32ba3e516: Preparing\n",
      "a51a3b48271d: Preparing\n",
      "a511d9654b02: Preparing\n",
      "2f1bd76bc703: Preparing\n",
      "8b2e8aaca9d1: Preparing\n",
      "8993b8ce917e: Preparing\n",
      "ac54c730c06b: Preparing\n",
      "a0cfa52f0f1c: Preparing\n",
      "75b79e19929c: Preparing\n",
      "4775b2f378bb: Preparing\n",
      "883eafdbe580: Preparing\n",
      "19d043c86cbc: Preparing\n",
      "8823818c4748: Preparing\n",
      "8993b8ce917e: Waiting\n",
      "ac54c730c06b: Waiting\n",
      "a0cfa52f0f1c: Waiting\n",
      "75b79e19929c: Waiting\n",
      "4775b2f378bb: Waiting\n",
      "883eafdbe580: Waiting\n",
      "19d043c86cbc: Waiting\n",
      "8823818c4748: Waiting\n",
      "a511d9654b02: Waiting\n",
      "a51a3b48271d: Waiting\n",
      "8b2e8aaca9d1: Waiting\n",
      "2f1bd76bc703: Waiting\n",
      "58907d6c372e: Pushed\n",
      "07a32ba3e516: Pushed\n",
      "a511d9654b02: Layer already exists\n",
      "2f1bd76bc703: Layer already exists\n",
      "8b2e8aaca9d1: Layer already exists\n",
      "8993b8ce917e: Layer already exists\n",
      "834ea553a725: Pushed\n",
      "ac54c730c06b: Layer already exists\n",
      "a0cfa52f0f1c: Layer already exists\n",
      "75b79e19929c: Layer already exists\n",
      "4775b2f378bb: Layer already exists\n",
      "883eafdbe580: Layer already exists\n",
      "19d043c86cbc: Layer already exists\n",
      "8823818c4748: Layer already exists\n",
      "a51a3b48271d: Pushed\n",
      "b426a3435ac3: Pushed\n",
      "fcc6929d67eb: Pushed\n",
      "latest: digest: sha256:558e6827201d0269fca603f1e2cdf32c0370d9fdad232f05551d1393af8c6cdf size: 3887\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            IMAGES                                                              STATUS\n",
      "fc70c8e5-4066-4eb9-bc0f-82e4926f9a43  2021-03-08T06:39:20+00:00  4M18S     gs://youtubelist-256522_cloudbuild/source/1615185559.530601-71e7af90612c4339bf82bee14bbed4db.tgz  gcr.io/youtubelist-256522/babyweight-pipeline-traintuned (+1 more)  SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 10 file(s) totalling 17.3 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://youtubelist-256522_cloudbuild/source/1615185559.530601-71e7af90612c4339bf82bee14bbed4db.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/youtubelist-256522/locations/global/builds/fc70c8e5-4066-4eb9-bc0f-82e4926f9a43].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/fc70c8e5-4066-4eb9-bc0f-82e4926f9a43?project=364153344912].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pipelines/containers\n",
    "bash build_all.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the Docker images work properly ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching local job ... hang on\n",
      "/usr/local/lib/python2.7/dist-packages/apache_beam/runners/direct/direct_runner.py:342: DeprecationWarning: options is deprecated since First stable release.. References to <pipeline>.options will not be supported\n",
      "  pipeline.replace_all(_get_transform_overrides(pipeline.options))\n",
      "INFO:root:Running pipeline with DirectRunner.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "WARNING:root:Dataset youtubelist-256522:temp_dataset_dd8cee4aa1d84980bef984007bd11fca does not exist so we will create it as temporary with location=None\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "WARNING:root:Dataset youtubelist-256522:temp_dataset_09210de16d52482cb8dc5cf5aa91e8e1 does not exist so we will create it as temporary with location=None\n",
      "INFO:root:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:root:Renamed 1 shards in 0.12 seconds.\n",
      "INFO:root:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:root:Renamed 1 shards in 0.12 seconds.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!docker run -t gcr.io/ai-analytics-solutions/babyweight-pipeline-bqtocsv:latest --project $PROJECT  --bucket $BUCKET --mode local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Upload and execute pipeline\n",
    "\n",
    "Upload to the Kubeflow pipeline cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://7d7bd1724973ff3f-dot-us-central1.pipelines.googleusercontent.com/#/experiments/details/b588d052-45b0-41dd-979d-5234f3cc3ad5\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://7d7bd1724973ff3f-dot-us-central1.pipelines.googleusercontent.com/#/runs/details/0fd9d5a2-dc81-49a4-b812-ccb091d224b0\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pipelines.containers.pipeline import mlp_babyweight\n",
    "\n",
    "args = {\n",
    "    'project' : PROJECT, \n",
    "    'bucket' : BUCKET\n",
    "}\n",
    "os.environ['HPARAM_JOB'] = 'babyweight_200207_231639'\n",
    "\n",
    "pipeline = client.create_run_from_pipeline_func(mlp_babyweight.preprocess_train_and_deploy, args)\n",
    "\n",
    "#os.environ['HPARAM_JOB'] = 'babyweight_200207_231639' # change to job from complete step\n",
    "#pipeline = client.create_run_from_pipeline_func(mlp_babyweight.train_and_deploy, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ '[' 2 -ne 2 ']'\n",
      "+ HYPERJOB=babyweight_210308_033518\n",
      "+ BUCKET=cesar-pipelines-kfp\n",
      "+ TFVERSION=1.8\n",
      "+ REGION=us-central1\n",
      "+ echo 'Extracting information for job babyweight_210308_033518'\n",
      "Extracting information for job babyweight_210308_033518\n",
      "++ gcloud ai-platform jobs describe babyweight_210308_033518 --format 'value(trainingOutput.trials.finalMetric.objectiveValue.slice(0))'\n",
      "ERROR: (gcloud.ai-platform.jobs.describe) You do not currently have an active account selected.\n",
      "Please run:\n",
      "\n",
      "  $ gcloud auth login\n",
      "\n",
      "to obtain new credentials.\n",
      "\n",
      "If you have already logged in with a different account:\n",
      "\n",
      "    $ gcloud config set account ACCOUNT\n",
      "\n",
      "to select an already authenticated account to use.\n",
      "+ RMSE=\n"
     ]
    }
   ],
   "source": [
    "!docker run -t gcr.io/youtubelist-256522/babyweight-pipeline-traintuned:latest babyweight_210308_033518 cesar-pipelines-kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untagged: gcr.io/youtubelist-256522/babyweight-pipeline-traintuned:latest\n",
      "Untagged: gcr.io/youtubelist-256522/babyweight-pipeline-traintuned@sha256:16b8184599ef935416088663ab9c6b35c67a1243942bef5d0fc16993d7333d86\n",
      "Deleted: sha256:27ad37d6e10ec6920911fbd0e480bb600f85f1c4624c4d4023b2850b2a9a573b\n"
     ]
    }
   ],
   "source": [
    "!docker image rm -f 27ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +rwx pipelines/containers/traintuned/train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ '[' 2 -ne 2 ']'\n",
      "+ HYPERJOB=babyweight_210308_033518\n",
      "+ BUCKET=cesar-pipelines-kfp\n",
      "+ TFVERSION=1.8\n",
      "+ REGION=us-central1\n",
      "+ echo 'Extracting information for job babyweight_210308_033518'\n",
      "Extracting information for job babyweight_210308_033518\n",
      "++ gcloud ai-platform jobs describe babyweight_210308_033518 --format 'value(trainingOutput.trials.finalMetric.objectiveValue.slice(0))'\n",
      "+ RMSE=\n",
      "++ gcloud ai-platform jobs describe babyweight_210308_033518 --format 'value(trainingOutput.trials.hyperparameters.nnsize.slice(0))'\n",
      "+ NNSIZE=261\n",
      "++ gcloud ai-platform jobs describe babyweight_210308_033518 --format 'value(trainingOutput.trials.hyperparameters.batch_size.slice(0))'\n",
      "+ BATCHSIZE=8\n",
      "++ gcloud ai-platform jobs describe babyweight_210308_033518 --format 'value(trainingOutput.trials.hyperparameters.nembeds.slice(0))'\n",
      "+ NEMBEDS=14\n",
      "++ gcloud ai-platform jobs describe babyweight_210308_033518 --format 'value(trainingOutput.trials.trialId.slice(0))'\n",
      "+ TRIALID=20\n",
      "+ echo 'Continuing to train model in 20 with nnsize=261 batch_size=8 nembeds=14'\n",
      "Continuing to train model in 20 with nnsize=261 batch_size=8 nembeds=14\n",
      "+ CODEDIR=/babyweight/src/training-data-analyst/courses/machine_learning/deepdive/06_structured\n",
      "+ FROMDIR=gs://cesar-pipelines-kfp/babyweight/hyperparam/20\n",
      "+ OUTDIR=gs://cesar-pipelines-kfp/babyweight/traintuned\n",
      "+ export PYTHONPATH=/babyweight/src/training-data-analyst/courses/machine_learning/deepdive/06_structured/babyweight:\n",
      "+ PYTHONPATH=/babyweight/src/training-data-analyst/courses/machine_learning/deepdive/06_structured/babyweight:\n",
      "+ gsutil -m rm -rf gs://cesar-pipelines-kfp/babyweight/traintuned\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/#1615180764234693...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/checkpoint#1615180766144732...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/eval/events.out.tfevents.1615175789.gke-cml-0308-033602--n1-highcpu-8-43e-930c88cf-dbk5#1615180736300158...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/eval/events.out.tfevents.1615180750.0bf846e5d3e6#1615180751356616...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/export/exporter/1615175790/variables/variables.index#1615180736646144...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/export/exporter/1615180751/variables/variables.index#1615180758907098...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/events.out.tfevents.1615175782.gke-cml-0308-033602--n1-highcpu-8-43e-930c88cf-sr3f#1615180736352223...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/graph.pbtxt#1615180761798094...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/export/exporter/1615180751/variables/variables.data-00000-of-00001#1615180758565979...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/export/exporter/1615175790/saved_model.pb#1615180736408393...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/export/exporter/1615175790/variables/variables.data-00000-of-00002#1615180736636642...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/export/exporter/1615180751/saved_model.pb#1615180757908410...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/events.out.tfevents.1615180739.0bf846e5d3e6#1615180767613668...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/events.out.tfevents.1615175776.gke-cml-0308-033602--n1-highcpu-8-43e-930c88cf-dbk5#1615180736372623...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/export/exporter/1615180751/variables/#1615180758243125...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/model.ckpt-0.data-00000-of-00004#1615180736494409...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/export/exporter/1615180751/#1615180757555896...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/export/exporter/1615175790/variables/variables.data-00001-of-00002#1615180736618456...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/model.ckpt-0.data-00001-of-00004#1615180736478010...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/model.ckpt-0.data-00000-of-00001#1615180764753477...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/model.ckpt-0.data-00002-of-00004#1615180736469622...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/model.ckpt-0.data-00003-of-00004#1615180736529728...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/model.ckpt-0.index#1615180765175670...\n",
      "Removing gs://cesar-pipelines-kfp/babyweight/traintuned/model.ckpt-0.meta#1615180767119258...\n",
      "/ [24/24 objects] 100% Done                                                     \n",
      "Operation completed over 24 objects.                                             \n",
      "+ gsutil -m cp -r gs://cesar-pipelines-kfp/babyweight/hyperparam/20 gs://cesar-pipelines-kfp/babyweight/traintuned\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/checkpoint...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/eval/events.out.tfevents.1615175789.gke-cml-0308-033602--n1-highcpu-8-43e-930c88cf-dbk5...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/events.out.tfevents.1615175782.gke-cml-0308-033602--n1-highcpu-8-43e-930c88cf-sr3f...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/model.ckpt-0.data-00003-of-00004...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/events.out.tfevents.1615175776.gke-cml-0308-033602--n1-highcpu-8-43e-930c88cf-dbk5...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/export/exporter/1615175790/variables/variables.data-00000-of-00002...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/model.ckpt-0.data-00000-of-00004...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/model.ckpt-0.data-00001-of-00004...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/export/exporter/1615175790/variables/variables.index...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/export/exporter/1615175790/variables/variables.data-00001-of-00002...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/export/exporter/1615175790/saved_model.pb...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/model.ckpt-0.data-00002-of-00004...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/graph.pbtxt...\n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/model.ckpt-0.meta...  \n",
      "Copying gs://cesar-pipelines-kfp/babyweight/hyperparam/20/model.ckpt-0.index... \n",
      "+ python -m trainer.task --job-dir=gs://cesar-pipelines-kfp/babyweight/traintuned --bucket=cesar-pipelines-kfp --output_dir=gs://cesar-pipelines-kfp/babyweight/traintuned --eval_steps=10 --nnsize=261 --batch_size=8 --nembeds=14 --train_examples=2000\n",
      "/opt/conda/bin/python: Error while finding module specification for 'trainer.task' (ModuleNotFoundError: No module named 'trainer')\n"
     ]
    }
   ],
   "source": [
    "!./pipelines/containers/traintuned/train.sh babyweight_210308_033518 cesar-pipelines-kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_explore.ipynb\t\t4_preproc.ipynb      7_pipelines.ipynb\tpipelines\n",
      "2_sample.ipynb\t\t4_preproc_tft.ipynb  README.md\t\tserving\n",
      "3_keras_dnn.ipynb\t5_train.ipynb\t     babyweight\t\ttrain.csv\n",
      "3_keras_wd.ipynb\t5_train_bqml.ipynb   babyweight_tf2\n",
      "3_tensorflow_dnn.ipynb\t5_train_keras.ipynb  eval.csv\n",
      "3_tensorflow_wd.ipynb\t6_deploy.ipynb\t     labs\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
